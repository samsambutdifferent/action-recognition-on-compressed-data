{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Right Left up down spatial 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:25:20.452226Z",
     "iopub.status.busy": "2023-12-28T10:25:20.451934Z",
     "iopub.status.idle": "2023-12-28T10:25:25.112862Z",
     "shell.execute_reply": "2023-12-28T10:25:25.111810Z",
     "shell.execute_reply.started": "2023-12-28T10:25:20.452199Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "from frame_generator import FrameGenerator\n",
    "from model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:25:25.114591Z",
     "iopub.status.busy": "2023-12-28T10:25:25.114083Z",
     "iopub.status.idle": "2023-12-28T10:25:25.164257Z",
     "shell.execute_reply": "2023-12-28T10:25:25.162809Z",
     "shell.execute_reply.started": "2023-12-28T10:25:25.114563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes being compared ['Pushing something from left to right'\n",
      " 'Pushing something from right to left' 'Moving something up'\n",
      " 'Moving something down']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data_sp7_right_left_up_down_1200\"\n",
    "NOTEBOOK_NAME = \"2_2d_plus_1_rlud_sp7\"\n",
    "RESULTS_PATH = DATA_PATH + \"/\" + NOTEBOOK_NAME\n",
    "\n",
    "# PARAMS\n",
    "# number of frames taken from each video\n",
    "n_frames = 36\n",
    "# number of frames skipped from each video\n",
    "frame_step = 2\n",
    "batch_size = 8\n",
    "# Define the dimensions of one frame in the set of frames created\n",
    "HEIGHT = 13\n",
    "WIDTH = 7\n",
    "\n",
    "assert(os.path.isdir(DATA_PATH ))\n",
    "\n",
    "if not os.path.isdir(RESULTS_PATH):\n",
    "    os.mkdir(RESULTS_PATH)\n",
    "\n",
    "index_df = pd.read_csv(f'{DATA_PATH}/indx_df.csv')\n",
    "\n",
    "print(f\"classes being compared {index_df['category'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:25:25.167987Z",
     "iopub.status.busy": "2023-12-28T10:25:25.167182Z",
     "iopub.status.idle": "2023-12-28T10:25:50.092151Z",
     "shell.execute_reply": "2023-12-28T10:25:50.091282Z",
     "shell.execute_reply.started": "2023-12-28T10:25:25.167952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 46.21875\n",
      "Maximum: 71\n",
      "Minimum: 30\n"
     ]
    }
   ],
   "source": [
    "from validate_files import get_video_lengths\n",
    "\n",
    "lengths_array = get_video_lengths(f\"./{DATA_PATH}/test/\")\n",
    "np.append(lengths_array, get_video_lengths(f\"./{DATA_PATH}/train/\"))\n",
    "np.append(lengths_array, get_video_lengths(f\"./{DATA_PATH}/validation/\"))\n",
    "\n",
    "# Calculate average\n",
    "average = np.mean(lengths_array)\n",
    "\n",
    "# Calculate maximum\n",
    "maximum = np.max(lengths_array)\n",
    "\n",
    "# Calculate minimum\n",
    "minimum = np.min(lengths_array)\n",
    "\n",
    "print(\"Average:\", average)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Minimum:\", minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess video data\n",
    "\n",
    "Load something something data tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:25:50.093631Z",
     "iopub.status.busy": "2023-12-28T10:25:50.093372Z",
     "iopub.status.idle": "2023-12-28T10:25:51.974908Z",
     "shell.execute_reply": "2023-12-28T10:25:51.974226Z",
     "shell.execute_reply.started": "2023-12-28T10:25:50.093606Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.FlatMapDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 22:10:31.606970: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/python/3.10.13/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-01-04 22:10:31.607002: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-01-04 22:10:31.607031: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-5f4282): /proc/driver/nvidia/version does not exist\n",
      "2024-01-04 22:10:31.607336: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "subset_paths = {\n",
    "    \"test\": Path(f'{DATA_PATH}/test'),\n",
    "    \"train\": Path(f'{DATA_PATH}/train'),\n",
    "    \"val\": Path(f'{DATA_PATH}/validation'),\n",
    "}\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "    tf.TensorSpec(shape = (), dtype = tf.int16)\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(subset_paths['train'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        height=HEIGHT,\n",
    "        width=WIDTH,\n",
    "        training=True\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "# Batch the data\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(\n",
    "        subset_paths['val'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        height=HEIGHT,\n",
    "        width=WIDTH,\n",
    "        training=False\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "# Batch the data\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(\n",
    "        subset_paths['test'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        height=HEIGHT,\n",
    "        width=WIDTH,\n",
    "        training=False\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "\n",
    "print(type(test_ds))\n",
    "\n",
    "# Batch the data\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "print(type(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:25:51.976749Z",
     "iopub.status.busy": "2023-12-28T10:25:51.975962Z",
     "iopub.status.idle": "2023-12-28T10:25:55.212667Z",
     "shell.execute_reply": "2023-12-28T10:25:55.211561Z",
     "shell.execute_reply.started": "2023-12-28T10:25:51.976721Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(n_frames=n_frames, height=HEIGHT, width=WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:25:55.214083Z",
     "iopub.status.busy": "2023-12-28T10:25:55.213832Z",
     "iopub.status.idle": "2023-12-28T10:25:55.384892Z",
     "shell.execute_reply": "2023-12-28T10:25:55.383609Z",
     "shell.execute_reply.started": "2023-12-28T10:25:55.214059Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x7fe76ce23940>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing tensor is setup correct\n",
    "iter(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:25:55.387773Z",
     "iopub.status.busy": "2023-12-28T10:25:55.386589Z",
     "iopub.status.idle": "2023-12-28T10:26:00.535407Z",
     "shell.execute_reply": "2023-12-28T10:26:00.534289Z",
     "shell.execute_reply.started": "2023-12-28T10:25:55.387704Z"
    }
   },
   "outputs": [],
   "source": [
    "frames, label = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:26:00.537294Z",
     "iopub.status.busy": "2023-12-28T10:26:00.536961Z",
     "iopub.status.idle": "2023-12-28T10:26:00.542153Z",
     "shell.execute_reply": "2023-12-28T10:26:00.541283Z",
     "shell.execute_reply.started": "2023-12-28T10:26:00.537267Z"
    }
   },
   "outputs": [],
   "source": [
    "model.build(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:26:36.994607Z",
     "iopub.status.busy": "2023-12-28T10:26:36.994243Z",
     "iopub.status.idle": "2023-12-28T10:26:36.999930Z",
     "shell.execute_reply": "2023-12-28T10:26:36.998918Z",
     "shell.execute_reply.started": "2023-12-28T10:26:36.994579Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_runs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:26:37.251246Z",
     "iopub.status.busy": "2023-12-28T10:26:37.250679Z",
     "iopub.status.idle": "2023-12-28T10:26:37.294203Z",
     "shell.execute_reply": "2023-12-28T10:26:37.293285Z",
     "shell.execute_reply.started": "2023-12-28T10:26:37.251205Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_runs += 1\n",
    "\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              metrics=[\n",
    "                    'accuracy',\n",
    "                ]\n",
    "            )\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    RESULTS_PATH + '/model-runs-' + str(previous_runs) + '-cp-{epoch:02d}-{val_loss:.2f}.ckpt',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:26:37.767666Z",
     "iopub.status.busy": "2023-12-28T10:26:37.767179Z",
     "iopub.status.idle": "2023-12-28T10:26:38.122377Z",
     "shell.execute_reply": "2023-12-28T10:26:38.121360Z",
     "shell.execute_reply.started": "2023-12-28T10:26:37.767617Z"
    }
   },
   "outputs": [],
   "source": [
    "latest = tf.train.latest_checkpoint(RESULTS_PATH)\n",
    "\n",
    "if latest is not None:\n",
    "    print(f\"loading model from weights: {latest}\")\n",
    "    model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-28T10:26:40.555919Z",
     "iopub.status.busy": "2023-12-28T10:26:40.554711Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m previously_run_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpreviously_run_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    977\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[0;32m--> 980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    983\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    984\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "previously_run_epochs = 0\n",
    "history = model.fit(\n",
    "        x=train_ds,\n",
    "        epochs = 50 - previously_run_epochs,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[checkpoint_callback, early_stopping],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T13:53:42.398836Z",
     "iopub.status.busy": "2023-12-24T13:53:42.398074Z",
     "iopub.status.idle": "2023-12-24T13:56:12.718886Z",
     "shell.execute_reply": "2023-12-24T13:56:12.717773Z",
     "shell.execute_reply.started": "2023-12-24T13:53:42.398798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 13:53:44.384908: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n",
      "2023-12-24 13:53:45.818856: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 7s 7s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-24 13:53:53.122601: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n",
      "2023-12-24 13:53:53.258134: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 1s 893ms/step\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "1/1 [==============================] - 1s 883ms/step\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 1s 896ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 896ms/step\n",
      "1/1 [==============================] - 1s 881ms/step\n",
      "1/1 [==============================] - 1s 878ms/step\n",
      "1/1 [==============================] - 1s 912ms/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 886ms/step\n",
      "1/1 [==============================] - 1s 907ms/step\n",
      "1/1 [==============================] - 1s 889ms/step\n",
      "1/1 [==============================] - 1s 889ms/step\n",
      "1/1 [==============================] - 1s 882ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "1/1 [==============================] - 1s 897ms/step\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 1s 918ms/step\n",
      "1/1 [==============================] - 1s 910ms/step\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 1s 906ms/step\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "1/1 [==============================] - 1s 893ms/step\n",
      "1/1 [==============================] - 1s 884ms/step\n",
      "1/1 [==============================] - 1s 907ms/step\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "1/1 [==============================] - 1s 893ms/step\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 901ms/step\n",
      "1/1 [==============================] - 1s 919ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 865ms/step\n",
      "1/1 [==============================] - 1s 886ms/step\n",
      "1/1 [==============================] - 1s 897ms/step\n",
      "1/1 [==============================] - 1s 896ms/step\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "1/1 [==============================] - 1s 908ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 915ms/step\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 1s 893ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "for batch in test_ds:\n",
    "    x, y = batch\n",
    "    true_labels.extend(y.numpy())\n",
    "    preds = model.predict(x)\n",
    "    preds = softmax(preds, axis=1)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    predictions.extend(preds)\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T13:56:12.721151Z",
     "iopub.status.busy": "2023-12-24T13:56:12.720798Z",
     "iopub.status.idle": "2023-12-24T13:56:12.734477Z",
     "shell.execute_reply": "2023-12-24T13:56:12.733482Z",
     "shell.execute_reply.started": "2023-12-24T13:56:12.721111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9166666666666666\n",
      "Class Pushing something from left to right: Precision: 0.9661016949152542, Recall: 0.95, F1 Score: 0.957983193277311\n",
      "Class Pushing something from right to left: Precision: 0.9734513274336283, Recall: 0.9166666666666666, F1 Score: 0.944206008583691\n",
      "Class Moving something up: Precision: 0.8296296296296296, Recall: 0.9333333333333333, F1 Score: 0.8784313725490196\n",
      "Class Moving something down: Precision: 0.9122807017543859, Recall: 0.8666666666666667, F1 Score: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "fg = FrameGenerator(\n",
    "    subset_paths['test'],\n",
    "    n_frames=n_frames,\n",
    "    index_df=index_df,\n",
    "    frame_step=frame_step,\n",
    "    training=False\n",
    ")\n",
    "class_id_value = {\n",
    "    fg.class_ids_for_name[x]: x for x in fg.class_ids_for_name.keys()\n",
    " }\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average=None)\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n",
    "for i, (prec, rec, f1) in enumerate(zip(precision, recall, f1_score)):\n",
    "    print(f\"Class {class_id_value[i]}: Precision: {prec}, Recall: {rec}, F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
