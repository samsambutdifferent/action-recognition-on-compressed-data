{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Right Left up down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:44:26.561446Z",
     "iopub.status.busy": "2023-12-19T15:44:26.561199Z",
     "iopub.status.idle": "2023-12-19T15:44:33.771268Z",
     "shell.execute_reply": "2023-12-19T15:44:33.769991Z",
     "shell.execute_reply.started": "2023-12-19T15:44:26.561417Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 21:26:32.654617: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-04 21:26:35.216368: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-01-04 21:26:35.216400: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-01-04 21:26:35.438495: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-04 21:26:39.129861: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-04 21:26:39.130107: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-01-04 21:26:39.130125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from frame_generator import FrameGenerator\n",
    "from model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:44:33.773836Z",
     "iopub.status.busy": "2023-12-19T15:44:33.773254Z",
     "iopub.status.idle": "2023-12-19T15:45:07.336344Z",
     "shell.execute_reply": "2023-12-19T15:45:07.335637Z",
     "shell.execute_reply.started": "2023-12-19T15:44:33.773809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 46.21875\n",
      "Maximum: 71\n",
      "Minimum: 30\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_video_lngth(video_path):\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Failed to open video: {video_path}\")\n",
    "        return -1\n",
    "\n",
    "    # Get the number of frames in the video\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    cap.release()\n",
    "    return length\n",
    "\n",
    "\n",
    "def get_video_lengths(folder_path):\n",
    "    # List to store the lengths of the videos\n",
    "    video_lengths = []\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".avi\"):  # Check for video files (e.g., .mp4)\n",
    "            video_path = os.path.join(folder_path, filename)\n",
    "\n",
    "            length = get_video_lngth(video_path)\n",
    "            if length == -1:\n",
    "                continue\n",
    "\n",
    "            video_lengths.append(length)\n",
    "\n",
    "            # Release the VideoCapture object\n",
    "            \n",
    "\n",
    "    return np.array(video_lengths)\n",
    "\n",
    "lengths_array = get_video_lengths(\"./data_right_left_up_down_1200/test/\")\n",
    "np.append(lengths_array, get_video_lengths(\"./data_right_left_up_down_1200/train/\"))\n",
    "np.append(lengths_array, get_video_lengths(\"./data_right_left_up_down_1200/validation/\"))\n",
    "\n",
    "# Calculate average\n",
    "average = np.mean(lengths_array)\n",
    "\n",
    "# Calculate maximum\n",
    "maximum = np.max(lengths_array)\n",
    "\n",
    "# Calculate minimum\n",
    "minimum = np.min(lengths_array)\n",
    "\n",
    "print(\"Average:\", average)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Minimum:\", minimum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:48:49.117687Z",
     "iopub.status.busy": "2023-12-19T15:48:49.117319Z",
     "iopub.status.idle": "2023-12-19T15:48:49.149593Z",
     "shell.execute_reply": "2023-12-19T15:48:49.148466Z",
     "shell.execute_reply.started": "2023-12-19T15:48:49.117662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes being compared ['Pushing something from left to right'\n",
      " 'Pushing something from right to left' 'Moving something up'\n",
      " 'Moving something down']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data_right_left_up_down_1200\"\n",
    "NOTEBOOK_NAME = \"2_2d_plus_1\"\n",
    "RESULTS_PATH = DATA_PATH + \"/\" + NOTEBOOK_NAME\n",
    "\n",
    "# PARAMS\n",
    "# number of frames taken from each video\n",
    "n_frames = 36\n",
    "# number of frames skipped from each video\n",
    "frame_step = 2\n",
    "batch_size = 8\n",
    "# Define the dimensions of one frame in the set of frames created\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "assert(os.path.isdir(DATA_PATH ))\n",
    "\n",
    "if not os.path.isdir(RESULTS_PATH):\n",
    "    os.mkdir(RESULTS_PATH)\n",
    "\n",
    "index_df = pd.read_csv(f'{DATA_PATH}/indx_df.csv')\n",
    "\n",
    "print(f\"classes being compared {index_df['category'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess video data\n",
    "\n",
    "Load something something data tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:48:50.616240Z",
     "iopub.status.busy": "2023-12-19T15:48:50.614606Z",
     "iopub.status.idle": "2023-12-19T15:48:53.176681Z",
     "shell.execute_reply": "2023-12-19T15:48:53.175629Z",
     "shell.execute_reply.started": "2023-12-19T15:48:50.616173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.FlatMapDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-04 21:28:16.742739: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/python/3.10.13/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-01-04 21:28:16.752256: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-01-04 21:28:16.752289: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (codespaces-5f4282): /proc/driver/nvidia/version does not exist\n",
      "2024-01-04 21:28:16.767203: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "subset_paths = {\n",
    "    \"test\": Path(f'{DATA_PATH}/test'),\n",
    "    \"train\": Path(f'{DATA_PATH}/train'),\n",
    "    \"val\": Path(f'{DATA_PATH}/validation'),\n",
    "}\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "    tf.TensorSpec(shape = (), dtype = tf.int16)\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(subset_paths['train'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        height=HEIGHT,\n",
    "        width=WIDTH,\n",
    "        training=True\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "# Batch the data\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(\n",
    "        subset_paths['val'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        height=HEIGHT,\n",
    "        width=WIDTH,\n",
    "        training=False\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "# Batch the data\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(\n",
    "        subset_paths['test'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        height=HEIGHT,\n",
    "        width=WIDTH,\n",
    "        training=False\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "\n",
    "print(type(test_ds))\n",
    "\n",
    "# Batch the data\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "print(type(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:48:53.178496Z",
     "iopub.status.busy": "2023-12-19T15:48:53.178249Z",
     "iopub.status.idle": "2023-12-19T15:48:55.884577Z",
     "shell.execute_reply": "2023-12-19T15:48:55.883590Z",
     "shell.execute_reply.started": "2023-12-19T15:48:53.178472Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(n_frames=n_frames, height=HEIGHT, width=WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:48:55.994555Z",
     "iopub.status.busy": "2023-12-19T15:48:55.994253Z",
     "iopub.status.idle": "2023-12-19T15:49:01.106032Z",
     "shell.execute_reply": "2023-12-19T15:49:01.104955Z",
     "shell.execute_reply.started": "2023-12-19T15:48:55.994530Z"
    }
   },
   "outputs": [],
   "source": [
    "frames, label = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:49:01.107842Z",
     "iopub.status.busy": "2023-12-19T15:49:01.107525Z",
     "iopub.status.idle": "2023-12-19T15:49:01.112723Z",
     "shell.execute_reply": "2023-12-19T15:49:01.111677Z",
     "shell.execute_reply.started": "2023-12-19T15:49:01.107816Z"
    }
   },
   "outputs": [],
   "source": [
    "model.build(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "Using BinaryCrossentropy as it is more effective for binary data\n",
    "\n",
    "from_logits is false because final layer includes a sigmoid activation,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:49:07.075702Z",
     "iopub.status.busy": "2023-12-19T15:49:07.075331Z",
     "iopub.status.idle": "2023-12-19T15:49:07.081754Z",
     "shell.execute_reply": "2023-12-19T15:49:07.080132Z",
     "shell.execute_reply.started": "2023-12-19T15:49:07.075673Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_runs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:49:07.941033Z",
     "iopub.status.busy": "2023-12-19T15:49:07.940680Z",
     "iopub.status.idle": "2023-12-19T15:49:07.962609Z",
     "shell.execute_reply": "2023-12-19T15:49:07.961786Z",
     "shell.execute_reply.started": "2023-12-19T15:49:07.941009Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_runs += 1\n",
    "\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              metrics=[\n",
    "                    'accuracy',\n",
    "                ]\n",
    "            )\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    RESULTS_PATH + '/model-runs-' + str(previous_runs) + '-cp-{epoch:02d}-{val_loss:.2f}.ckpt',\n",
    "    save_best_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:49:09.260849Z",
     "iopub.status.busy": "2023-12-19T15:49:09.259860Z",
     "iopub.status.idle": "2023-12-19T15:49:09.645084Z",
     "shell.execute_reply": "2023-12-19T15:49:09.644249Z",
     "shell.execute_reply.started": "2023-12-19T15:49:09.260799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from weights: data_right_left_up_down_1200/2_2d_plus_1_right_left_n_step_2_model_save_BinaryCrossentropy_precision_recall/model-runs-4-cp-12-0.24.ckpt\n"
     ]
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(RESULTS_PATH)\n",
    "\n",
    "if latest is not None:\n",
    "    print(f\"loading model from weights: {latest}\")\n",
    "    model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-19T15:49:17.530863Z",
     "iopub.status.busy": "2023-12-19T15:49:17.530489Z",
     "iopub.status.idle": "2023-12-19T19:07:16.597448Z",
     "shell.execute_reply": "2023-12-19T19:07:16.596313Z",
     "shell.execute_reply.started": "2023-12-19T15:49:17.530836Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 15:49:26.667879: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 18s 18s/step - loss: 0.1191 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 15:49:37.350841: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 22s 4s/step - loss: 0.0873 - accuracy: 1.0000 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 15:49:41.376517: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3/Unknown - 26s 4s/step - loss: 0.1435 - accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-19 15:49:44.775021: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480/480 [==============================] - 1690s 3s/step - loss: 0.1505 - accuracy: 0.9508 - val_loss: 0.2486 - val_accuracy: 0.9312\n",
      "Epoch 2/7\n",
      "480/480 [==============================] - 1675s 3s/step - loss: 0.1460 - accuracy: 0.9531 - val_loss: 0.2695 - val_accuracy: 0.9042\n",
      "Epoch 3/7\n",
      "480/480 [==============================] - 1662s 3s/step - loss: 0.1503 - accuracy: 0.9500 - val_loss: 0.2463 - val_accuracy: 0.9125\n",
      "Epoch 4/7\n",
      "480/480 [==============================] - 1663s 3s/step - loss: 0.1460 - accuracy: 0.9497 - val_loss: 0.3020 - val_accuracy: 0.9021\n",
      "Epoch 5/7\n",
      "480/480 [==============================] - 1647s 3s/step - loss: 0.1200 - accuracy: 0.9612 - val_loss: 0.3297 - val_accuracy: 0.8854\n",
      "Epoch 6/7\n",
      "480/480 [==============================] - 1751s 4s/step - loss: 0.1443 - accuracy: 0.9560 - val_loss: 0.3756 - val_accuracy: 0.8583\n",
      "Epoch 7/7\n",
      "480/480 [==============================] - 1781s 4s/step - loss: 0.1237 - accuracy: 0.9599 - val_loss: 0.2939 - val_accuracy: 0.8917\n"
     ]
    }
   ],
   "source": [
    "previously_run_epochs = 8 + 11 + 12 + 12\n",
    "\n",
    "history = model.fit(\n",
    "        x=train_ds,\n",
    "        epochs = 50 - previously_run_epochs,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[checkpoint_callback, early_stopping],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy, average precision,  average recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 17:53:38.140754: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1104674816 exceeds 10% of free system memory.\n",
      "2023-12-07 17:53:40.973318: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1104674816 exceeds 10% of free system memory.\n",
      "2023-12-07 17:53:41.878746: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1104674816 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 10s 10s/step - loss: 0.6355 - accuracy: 0.6250 - precision: 0.6667 - recall: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 17:53:46.245460: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1104674816 exceeds 10% of free system memory.\n",
      "2023-12-07 17:53:49.054489: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1104674816 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 264s 9s/step - loss: 0.6022 - accuracy: 0.7000 - precision: 0.7400 - recall: 0.6167\n",
      "Loss: 0.6021633744239807\n",
      "Accuracy: 0.699999988079071\n",
      "average Precision: 0.7400000095367432\n",
      "average Recall: 0.6166666746139526\n"
     ]
    }
   ],
   "source": [
    "## In future should have all 4 metrics but now just has loss and accuracy\n",
    "loss, accuracy, precision, recall = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"average Precision: {precision}\")\n",
    "print(f\"average Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "for batch in test_ds:\n",
    "    x, y = batch\n",
    "    true_labels.extend(y.numpy())\n",
    "    preds = model.predict(x)\n",
    "    preds = softmax(preds, axis=1)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    predictions.extend(preds)\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = FrameGenerator(\n",
    "    subset_paths['test'],\n",
    "    n_frames=n_frames,\n",
    "    index_df=index_df,\n",
    "    frame_step=frame_step,\n",
    "    training=False\n",
    ")\n",
    "class_id_value = {\n",
    "    fg.class_ids_for_name[x]: x for x in fg.class_ids_for_name.keys()\n",
    " }\n",
    "\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average=None)\n",
    "\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n",
    "for i, (prec, rec, f1) in enumerate(zip(precision, recall, f1_score)):\n",
    "    print(f\"Class {class_id_value[i]}: Precision: {prec}, Recall: {rec}, F1 Score: {f1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
