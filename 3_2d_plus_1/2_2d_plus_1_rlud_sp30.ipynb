{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Right Left up down 1200 spatial 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:16:49.252499Z",
     "iopub.status.busy": "2023-12-27T13:16:49.252187Z",
     "iopub.status.idle": "2023-12-27T13:16:55.033513Z",
     "shell.execute_reply": "2023-12-27T13:16:55.031706Z",
     "shell.execute_reply.started": "2023-12-27T13:16:49.252471Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from frame_generator import FrameGenerator\n",
    "from model import create_model, visualise_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:16:55.036250Z",
     "iopub.status.busy": "2023-12-27T13:16:55.035432Z",
     "iopub.status.idle": "2023-12-27T13:16:55.065397Z",
     "shell.execute_reply": "2023-12-27T13:16:55.064599Z",
     "shell.execute_reply.started": "2023-12-27T13:16:55.036202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes being compared ['Pushing something from left to right'\n",
      " 'Pushing something from right to left' 'Moving something up'\n",
      " 'Moving something down']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"data_30_right_left_up_down_1200\"\n",
    "NOTEBOOK_NAME = \"2_2d_plus_1_rlud_sp30_1200_n_step_2\"\n",
    "RESULTS_PATH = DATA_PATH + \"/\" + NOTEBOOK_NAME\n",
    "\n",
    "# PARAMS\n",
    "# number of frames taken from each video\n",
    "n_frames = 36\n",
    "# number of frames skipped from each video\n",
    "frame_step = 2\n",
    "batch_size = 8\n",
    "# Define the dimensions of one frame in the set of frames created\n",
    "HEIGHT = 224\n",
    "WIDTH = 224\n",
    "\n",
    "assert(os.path.isdir(DATA_PATH ))\n",
    "\n",
    "if not os.path.isdir(RESULTS_PATH):\n",
    "    os.mkdir(RESULTS_PATH)\n",
    "\n",
    "index_df = pd.read_csv(f'{DATA_PATH}/indx_df.csv')\n",
    "\n",
    "print(f\"classes being compared {index_df['category'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:17:50.148295Z",
     "iopub.status.busy": "2023-12-27T10:17:50.147593Z",
     "iopub.status.idle": "2023-12-27T10:18:12.439094Z",
     "shell.execute_reply": "2023-12-27T10:18:12.438456Z",
     "shell.execute_reply.started": "2023-12-27T10:17:50.148259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average: 46.21875\n",
      "Maximum: 71\n",
      "Minimum: 30\n"
     ]
    }
   ],
   "source": [
    "from validate_files import get_video_lengths\n",
    "\n",
    "lengths_array = get_video_lengths(f\"./{DATA_PATH}/test/\")\n",
    "np.append(lengths_array, get_video_lengths(f\"./{DATA_PATH}/train/\"))\n",
    "np.append(lengths_array, get_video_lengths(f\"./{DATA_PATH}/validation/\"))\n",
    "\n",
    "# Calculate average\n",
    "average = np.mean(lengths_array)\n",
    "\n",
    "# Calculate maximum\n",
    "maximum = np.max(lengths_array)\n",
    "\n",
    "# Calculate minimum\n",
    "minimum = np.min(lengths_array)\n",
    "\n",
    "print(\"Average:\", average)\n",
    "print(\"Maximum:\", maximum)\n",
    "print(\"Minimum:\", minimum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess video data\n",
    "\n",
    "Load something something data tf.data.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:16:55.068084Z",
     "iopub.status.busy": "2023-12-27T13:16:55.067503Z",
     "iopub.status.idle": "2023-12-27T13:16:56.793321Z",
     "shell.execute_reply": "2023-12-27T13:16:56.791910Z",
     "shell.execute_reply.started": "2023-12-27T13:16:55.068057Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.dataset_ops.FlatMapDataset'>\n",
      "<class 'tensorflow.python.data.ops.dataset_ops.BatchDataset'>\n"
     ]
    }
   ],
   "source": [
    "subset_paths = {\n",
    "    \"test\": Path(f'{DATA_PATH}/test'),\n",
    "    \"train\": Path(f'{DATA_PATH}/train'),\n",
    "    \"val\": Path(f'{DATA_PATH}/validation'),\n",
    "}\n",
    "\n",
    "output_signature = (\n",
    "    tf.TensorSpec(shape = (None, None, None, 3), dtype = tf.float32),\n",
    "    tf.TensorSpec(shape = (), dtype = tf.int16)\n",
    ")\n",
    "\n",
    "train_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(subset_paths['train'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        training=True\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "# Batch the data\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(\n",
    "        subset_paths['val'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        training=False\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "# Batch the data\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "    FrameGenerator(\n",
    "        subset_paths['test'],\n",
    "        n_frames=n_frames,\n",
    "        index_df=index_df,\n",
    "        frame_step=frame_step,\n",
    "        training=False\n",
    "    ),\n",
    "    output_signature = output_signature\n",
    ")\n",
    "\n",
    "print(type(test_ds))\n",
    "\n",
    "# Batch the data\n",
    "test_ds = test_ds.batch(batch_size)\n",
    "\n",
    "print(type(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:16:56.795507Z",
     "iopub.status.busy": "2023-12-27T13:16:56.795105Z",
     "iopub.status.idle": "2023-12-27T13:16:59.907053Z",
     "shell.execute_reply": "2023-12-27T13:16:59.905982Z",
     "shell.execute_reply.started": "2023-12-27T13:16:56.795471Z"
    }
   },
   "outputs": [],
   "source": [
    "model = create_model(n_frames=n_frames, height=HEIGHT, width=WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:16:59.909685Z",
     "iopub.status.busy": "2023-12-27T13:16:59.908784Z",
     "iopub.status.idle": "2023-12-27T13:16:59.982988Z",
     "shell.execute_reply": "2023-12-27T13:16:59.982008Z",
     "shell.execute_reply.started": "2023-12-27T13:16:59.909643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.data.ops.iterator_ops.OwnedIterator at 0x7f2bc8588ee0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing tensor is setup correct\n",
    "iter(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:16:59.984560Z",
     "iopub.status.busy": "2023-12-27T13:16:59.984265Z",
     "iopub.status.idle": "2023-12-27T13:17:04.891453Z",
     "shell.execute_reply": "2023-12-27T13:17:04.890581Z",
     "shell.execute_reply.started": "2023-12-27T13:16:59.984525Z"
    }
   },
   "outputs": [],
   "source": [
    "frames, label = next(iter(train_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:17:04.893361Z",
     "iopub.status.busy": "2023-12-27T13:17:04.893030Z",
     "iopub.status.idle": "2023-12-27T13:17:04.897823Z",
     "shell.execute_reply": "2023-12-27T13:17:04.896670Z",
     "shell.execute_reply.started": "2023-12-27T13:17:04.893334Z"
    }
   },
   "outputs": [],
   "source": [
    "model.build(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:17:04.900007Z",
     "iopub.status.busy": "2023-12-27T13:17:04.899514Z",
     "iopub.status.idle": "2023-12-27T13:17:04.971436Z",
     "shell.execute_reply": "2023-12-27T13:17:04.970440Z",
     "shell.execute_reply.started": "2023-12-27T13:17:04.899981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 36, 224, 22  0           []                               \n",
      "                                4, 3)]                                                            \n",
      "                                                                                                  \n",
      " conv2_plus1d (Conv2Plus1D)     (None, 36, 224, 224  3152        ['input_1[0][0]']                \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 36, 224, 224  64         ['conv2_plus1d[0][0]']           \n",
      " alization)                     , 16)                                                             \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                   (None, 36, 224, 224  0           ['batch_normalization[0][0]']    \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " resize_video (ResizeVideo)     (None, 36, 112, 112  0           ['re_lu[0][0]']                  \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " residual_main (ResidualMain)   (None, 36, 112, 112  6272        ['resize_video[0][0]']           \n",
      "                                , 16)                                                             \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 36, 112, 112  0           ['resize_video[0][0]',           \n",
      "                                , 16)                             'residual_main[0][0]']          \n",
      "                                                                                                  \n",
      " resize_video_1 (ResizeVideo)   (None, 36, 56, 56,   0           ['add[0][0]']                    \n",
      "                                16)                                                               \n",
      "                                                                                                  \n",
      " project (Project)              (None, 36, 56, 56,   608         ['resize_video_1[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " residual_main_1 (ResidualMain)  (None, 36, 56, 56,   20224      ['resize_video_1[0][0]']         \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 36, 56, 56,   0           ['project[0][0]',                \n",
      "                                32)                               'residual_main_1[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_2 (ResizeVideo)   (None, 36, 28, 28,   0           ['add_1[0][0]']                  \n",
      "                                32)                                                               \n",
      "                                                                                                  \n",
      " project_1 (Project)            (None, 36, 28, 28,   2240        ['resize_video_2[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " residual_main_2 (ResidualMain)  (None, 36, 28, 28,   80384      ['resize_video_2[0][0]']         \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 36, 28, 28,   0           ['project_1[0][0]',              \n",
      "                                64)                               'residual_main_2[0][0]']        \n",
      "                                                                                                  \n",
      " resize_video_3 (ResizeVideo)   (None, 36, 14, 14,   0           ['add_2[0][0]']                  \n",
      "                                64)                                                               \n",
      "                                                                                                  \n",
      " project_2 (Project)            (None, 36, 14, 14,   8576        ['resize_video_3[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " residual_main_3 (ResidualMain)  (None, 36, 14, 14,   320512     ['resize_video_3[0][0]']         \n",
      "                                128)                                                              \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 36, 14, 14,   0           ['project_2[0][0]',              \n",
      "                                128)                              'residual_main_3[0][0]']        \n",
      "                                                                                                  \n",
      " global_average_pooling3d (Glob  (None, 128)         0           ['add_3[0][0]']                  \n",
      " alAveragePooling3D)                                                                              \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['global_average_pooling3d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 4)            516         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 442,548\n",
      "Trainable params: 442,516\n",
      "Non-trainable params: 32\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:17:04.974248Z",
     "iopub.status.busy": "2023-12-27T13:17:04.973992Z",
     "iopub.status.idle": "2023-12-27T13:17:05.091973Z",
     "shell.execute_reply": "2023-12-27T13:17:05.090456Z",
     "shell.execute_reply.started": "2023-12-27T13:17:04.974222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "visualise_model(\n",
    "    model=model,\n",
    "    file_path=DATA_PATH + \"/model_summary.dot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model\n",
    "\n",
    "Using BinaryCrossentropy as it is more effective for binary data\n",
    "\n",
    "from_logits is false because final layer includes a sigmoid activation,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:17:05.094094Z",
     "iopub.status.busy": "2023-12-27T13:17:05.093806Z",
     "iopub.status.idle": "2023-12-27T13:17:05.099554Z",
     "shell.execute_reply": "2023-12-27T13:17:05.098290Z",
     "shell.execute_reply.started": "2023-12-27T13:17:05.094068Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_runs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:17:05.101181Z",
     "iopub.status.busy": "2023-12-27T13:17:05.100903Z",
     "iopub.status.idle": "2023-12-27T13:17:05.125457Z",
     "shell.execute_reply": "2023-12-27T13:17:05.124620Z",
     "shell.execute_reply.started": "2023-12-27T13:17:05.101155Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_runs += 1\n",
    "\n",
    "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer = keras.optimizers.Adam(learning_rate = 0.0001),\n",
    "              metrics=[\n",
    "                    'accuracy',\n",
    "                    # tf.keras.metrics.Precision(),\n",
    "                    # tf.keras.metrics.Recall()\n",
    "                    # tf.keras.metrics.Precision(class_id=0, name='precision_neg'),\n",
    "                    # tf.keras.metrics.Precision(class_id=1, name='precision_pos'),\n",
    "                    # tf.keras.metrics.Recall(class_id=0, name='recall_neg'),\n",
    "                    # tf.keras.metrics.Recall(class_id=1, name='recall_pos')\n",
    "                ]\n",
    "            )\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    RESULTS_PATH + '/model-runs-' + str(previous_runs) + '-cp-{epoch:02d}-{val_loss:.2f}.ckpt',\n",
    "    save_best_only=True,  # Save only the best model based on a monitored metric (e.g., val_loss), will only replace saved value if it is better\n",
    "    monitor='val_loss',\n",
    "    mode='min',  # 'min' for loss, 'max' for accuracy\n",
    "    save_weights_only=True\n",
    ")\n",
    "\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,  # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:17:05.127144Z",
     "iopub.status.busy": "2023-12-27T13:17:05.126727Z",
     "iopub.status.idle": "2023-12-27T13:17:05.510551Z",
     "shell.execute_reply": "2023-12-27T13:17:05.509595Z",
     "shell.execute_reply.started": "2023-12-27T13:17:05.127070Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model from weights: data_30_right_left_up_down_1200/2_2d_plus_1_rlud_sp30_1200_n_step_2/model-runs-6-cp-03-0.27.ckpt\n"
     ]
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(RESULTS_PATH)\n",
    "\n",
    "if latest is not None:\n",
    "    print(f\"loading model from weights: {latest}\")\n",
    "    model.load_weights(latest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T10:20:48.677854Z",
     "iopub.status.busy": "2023-12-27T10:20:48.677299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 10:20:56.744254: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1/Unknown - 17s 17s/step - loss: 0.1519 - accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 10:21:06.976382: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2/Unknown - 20s 3s/step - loss: 0.1382 - accuracy: 0.9375 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 10:21:09.940478: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3/Unknown - 23s 3s/step - loss: 0.1165 - accuracy: 0.9583"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 10:21:13.147074: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 173408256 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    223/Unknown - 678s 3s/step - loss: 0.2325 - accuracy: 0.9148"
     ]
    }
   ],
   "source": [
    "previously_run_epochs = 0 + 6 + 12 + 12 + 5 + 11\n",
    "history = model.fit(\n",
    "        x=train_ds,\n",
    "        epochs = 50 - previously_run_epochs,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=[checkpoint_callback, early_stopping],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:17:10.409435Z",
     "iopub.status.busy": "2023-12-27T13:17:10.409068Z",
     "iopub.status.idle": "2023-12-27T13:19:40.579492Z",
     "shell.execute_reply": "2023-12-27T13:19:40.578178Z",
     "shell.execute_reply.started": "2023-12-27T13:17:10.409409Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 903ms/step\n",
      "1/1 [==============================] - 1s 889ms/step\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 1s 900ms/step\n",
      "1/1 [==============================] - 1s 904ms/step\n",
      "1/1 [==============================] - 1s 997ms/step\n",
      "1/1 [==============================] - 1s 917ms/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 1s 901ms/step\n",
      "1/1 [==============================] - 1s 881ms/step\n",
      "1/1 [==============================] - 1s 897ms/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 1s 884ms/step\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 883ms/step\n",
      "1/1 [==============================] - 1s 879ms/step\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 1s 908ms/step\n",
      "1/1 [==============================] - 1s 898ms/step\n",
      "1/1 [==============================] - 1s 886ms/step\n",
      "1/1 [==============================] - 1s 879ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 878ms/step\n",
      "1/1 [==============================] - 1s 922ms/step\n",
      "1/1 [==============================] - 1s 917ms/step\n",
      "1/1 [==============================] - 1s 911ms/step\n",
      "1/1 [==============================] - 1s 895ms/step\n",
      "1/1 [==============================] - 1s 898ms/step\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 888ms/step\n",
      "1/1 [==============================] - 1s 894ms/step\n",
      "1/1 [==============================] - 1s 902ms/step\n",
      "1/1 [==============================] - 1s 896ms/step\n",
      "1/1 [==============================] - 1s 892ms/step\n",
      "1/1 [==============================] - 1s 901ms/step\n",
      "1/1 [==============================] - 1s 902ms/step\n",
      "1/1 [==============================] - 1s 913ms/step\n",
      "1/1 [==============================] - 1s 923ms/step\n",
      "1/1 [==============================] - 1s 891ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 890ms/step\n",
      "1/1 [==============================] - 1s 900ms/step\n",
      "1/1 [==============================] - 1s 911ms/step\n",
      "1/1 [==============================] - 1s 901ms/step\n",
      "1/1 [==============================] - 1s 887ms/step\n",
      "1/1 [==============================] - 1s 899ms/step\n",
      "1/1 [==============================] - 1s 901ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "true_labels = []\n",
    "predictions = []\n",
    "\n",
    "# Iterate over the batched test dataset\n",
    "for batch in test_ds:\n",
    "    x, y = batch  # x is the batch of features, y is the batch of labels\n",
    "    true_labels.extend(y.numpy())  # Store true labels\n",
    "    preds = model.predict(x)  # Generate predictions for the batch\n",
    "    preds = softmax(preds, axis=1)  # Apply softmax to convert logits to probabilities\n",
    "    preds = np.argmax(preds, axis=1)  # Get the class with the highest probability\n",
    "    predictions.extend(preds)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-27T13:19:40.582307Z",
     "iopub.status.busy": "2023-12-27T13:19:40.581935Z",
     "iopub.status.idle": "2023-12-27T13:19:40.597138Z",
     "shell.execute_reply": "2023-12-27T13:19:40.595786Z",
     "shell.execute_reply.started": "2023-12-27T13:19:40.582280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.8729166666666667\n",
      "Class Pushing something from left to right: Precision: 0.7905405405405406, Recall: 0.975, F1 Score: 0.8731343283582089\n",
      "Class Pushing something from right to left: Precision: 0.9401709401709402, Recall: 0.9166666666666666, F1 Score: 0.9282700421940928\n",
      "Class Moving something up: Precision: 0.8818181818181818, Recall: 0.8083333333333333, F1 Score: 0.8434782608695653\n",
      "Class Moving something down: Precision: 0.9047619047619048, Recall: 0.7916666666666666, F1 Score: 0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "fg = FrameGenerator(\n",
    "    subset_paths['test'],\n",
    "    n_frames=n_frames,\n",
    "    index_df=index_df,\n",
    "    frame_step=frame_step,\n",
    "    training=False\n",
    ")\n",
    "class_id_value = {\n",
    "    fg.class_ids_for_name[x]: x for x in fg.class_ids_for_name.keys()\n",
    " }\n",
    "\n",
    "# Convert lists to numpy arrays if they aren't already\n",
    "true_labels = np.array(true_labels)\n",
    "predictions = np.array(predictions)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "\n",
    "# Calculate precision, recall, and F1-score for each class\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(true_labels, predictions, average=None)\n",
    "\n",
    "# Print accuracy and F1-scores for each class\n",
    "print(f\"Overall Accuracy: {accuracy}\")\n",
    "for i, (prec, rec, f1) in enumerate(zip(precision, recall, f1_score)):\n",
    "    print(f\"Class {class_id_value[i]}: Precision: {prec}, Recall: {rec}, F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
